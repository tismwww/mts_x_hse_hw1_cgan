Комментарий по коду:
У меня не получилось установить ignite, несмотря на то, что я скачала его несколькими способами. Из-за того, что модель обучалась больше 10 часов, я решила, что без early stopping я не успею закончить домашнее задание вовремя, поэтому в данный момент эта модель существует в единственной сборке. Однако работа будет продолжаться, и новые версии с иной инициализацией будут загружены в этот репозиторий.


Письменная часть:

- Чем отличается Conditional GAN от обычного GAN? Объясните, как вводится условная информация в генератор и дискриминатор. (10%)

GAN – это глубинная нейронная сеть, которая создана для генерации контента по подобию данных, на которых эта модель обучалась. GAN представляет собой два блока – генератор и дискриминатор, – которые в процессе тренировки «соревнуются» между собой ради достижения наилучшего результата. Генератор производит данные по подобию тех, на которых модель обучается, а дискриминатор «учится» определять, реальное ли это изображение или сгенерированное.
По сравнению с обычным GAN Conditional GAN позволяет обрести больше контроля над типом получаемых изображений. Кроме того, так как на вход требуется в том числе получение размеченных данных, качество модели в среднем повышается. Эта модель также позволяет генерировать выводы непосредственно для классов или лейблов, которые необходимы. Это может быть полезно в случае, если модель тренируется на большом объеме разнообразных данных, а в процессе использования модели существует необходимость генерации данных с определенными характеристиками. На уровне формул отличие единственное: в формуле для Conditional GAN добавляется условная вероятность:
 
Это позволяет сделать так, чтобы тренировка дискриминатора и генератора производилась с учетом классов, что впоследствии позволит генерировать нужную информацию, ориентируясь на классы.
С точки зрения кода, большая часть также схожа с кодом для простого GAN. Отличие заключается в том, что в CGAN необходимо добавить embedding для создания вектора классов (лейблов) и в генератор, и в дискриминатор. Так, например, можно объединить векторное представление изображения (или другого типа данных, на которых обучается модель) и классы в список. В таком случае при обучении размеченные данные будут рассматриваться в совокупности с лейблами, тем самым делая возможным генерацию разных изображений для разных лейблов на этой основе. 

Использованные материалы:
1.	https://deeplearning.cs.cmu.edu/F23/document/slides/lec25.GAN2.pdf#:~:text=Generative%20Adversarial%20Networks%20%E2%80%93%20Part,be%20close%20to%201
2.	https://blog.paperspace.com/complete-guide-to-gans/#generator-phase
3.	https://blog.paperspace.com/conditional-generative-adversarial-networks/


- Почему обучение GAN может быть нестабильным, и какие техники помогают стабилизировать процесс? (10%)

Обучение GAN может быть нестабильным из-за того, что он сильно подвержен следующим проблемам:
1.	Исчезающие градиенты: дискриминатор может стать слишком сильным, из-за чего параметры перестанут эффективно обновляться. Это происходит на этапе данного вычисления:
 
Предотвратить раннее насыщение градиента можно, максимизируя вместо этого log(D(G(z)))
2.	Сбой режима: генератор может научиться генерировать только ограниченный набор выборок, игнорируя разнообразие реального распределения данных. Это приводит к некачественным генерируемым выборкам. 
3.	Колебания: Генератор и дискриминатор могут колебаться между различными стратегиями, препятствуя достижению устойчивого равновесия. Это является следствием того, что мы одновременно минимизируем и максимизируем функцию по генератору и дискриминатору.

Пути решения описанных проблем:
1.	Градиентный штраф: регуляризация, добавленная в функцию потерь. Ограничивается норма градиента критического значения по отношению к его входным данным. Изначально разрабатывалось для WGAN, но может эффективно использоваться для любых моделей GAN. Также может использоваться спектральная нормализация путем нормализации весовых матриц дискриминатора по их большему сингулярному значению, что позволяет сделать модель более стабильной.
2.	Распознавание minibatch: метод, позволяющий дискриминатору учитывать взаимосвязь между выборками и minibatch’ами. 
3.	Постепенный рост GANs: увеличение GAN представляет собой метод обучения, представляющий постепенное увеличение разрешения генерируемых выборок. Сначала генерируются изображения с низким разрешением, потом постепенно к генератору и дискриминатору добавляются дополнительные слои, что повышает стабильность обучения. 
Кроме того, можно использовать дополнительные метрики для оценки сопоставимости распределения сгенерированных данных и данных для обучения:
1.	Inception Score (IS): измеряет качество и разнообразие сгенерированных выборок путем сравнения их распределения по классам с распределением реальных данных.
 
2.	Frechet Inception Distance (FID): показатель, который сравнивает статистику сгенерированных выборок и реальных данных в пространстве признаков предварительно обученной нейронной сети
 
Использованные материалы:
1.	https://deeplearning.cs.cmu.edu/F23/document/slides/lec25.GAN2.pdf#:~:text=Generative%20Adversarial%20Networks%20%E2%80%93%20Part,be%20close%20to%201
2.	https://saturncloud.io/glossary/training-stability-in-gans/#:~:text=Several%20factors%20contribute%20to%20the,and%20update%20its%20parameters%20effectively.
3.	http://arxiv.org/abs/1704.00028
4.	https://arxiv.org/abs/1710.10196 
5.	https://ahujaniharika95.medium.com/inception-score-is-and-fr%C3%A9chet-inception-distance-fid-explained-2bc28a4faea7 


- Какую роль играет латентное пространство в генерации изображений? Как условная информация влияет на него в CGAN? (10%)

Генерация изображений посредством GAN подразумевает получение генератором вектора из латентного пространства - латентное пространство является первым слоем в сети прямой связи (feed-forward network). Оно предоставляет представление в меньшем масштабе (lower-dimensional representation), предназначенное для отображения структуры и взаимосвязей, лежащих в основе этих данных. То есть, в латентном пространстве может исключаться нерелевантная информация, а оставаться – самая ключевая. При этом чем более похожими будут данные, тем ближе будут вектора этих данных в пространстве. 
На практике модель учится кодировать скрытое пространство, наиболее подходящее для точного выполнения задачи, которой ее обучают. В процессе обучение генератор учится отображать признаки в латентное пространство, видоизменяя его. В результате обучения модели на конкретных данных получается латентное пространство, которое, как уже было сказано выше, содержит обобщенные данные по результатам обучения – lower-dimensional representation – которое может быть извлечено и использовано далее для непосредственной генерации фотографий уже как результата натренированной модели.
В CGAN генератор может принимать в качестве входных данных вектор из латентного пространства и метку классов (условие). Это условие направляет процесс генерации для получения выходных данных, соответствующих заданным условиям.
Алгоритм работы генератора выглядит так:
1) Входной шум и условие (one-hot вектор) обычно объединяются и преобразуются в сети генератора.
2) Генератор синтезирует реалистичные образцы данных, связанные с условиями (лейблами/классами)
3) Благодаря включению условия генератор учится сопоставлять входной шум (вектор из латентного пространства) и условия с соответствующими выходными выборками более целенаправленным и управляемым образом.


Использованные материалы:
1.	https://medium.com/@boutnaru/the-artificial-intelligence-journey-latent-space-292ae1d29d00
2.	https://openaccess.thecvf.com/content_CVPR_2019/papers/Karras_A_Style-Based_Generator_Architecture_for_Generative_Adversarial_Networks_CVPR_2019_paper.pdf#:~:text=convolution%20layer%20based%20on%20the,levelattributes
3.	https://machinelearningmastery.com/how-to-interpolate-and-perform-vector-arithmetic-with-faces-using-a-generative-adversarial-network/
4.	https://arxiv.org/pdf/1411.1784 
5.	https://ankittaxak5713.medium.com/conditional-gan-e8c983d97b77


